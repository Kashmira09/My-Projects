# -*- coding: utf-8 -*-
"""Code_Kashmira_Ghag.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YvzdM6WtZf_8sss6jGm0ju7waJLv0Ide

Data Preparation
"""

from pandas import read_csv,DataFrame,get_dummies,Series
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn import metrics
from sklearn.model_selection import GridSearchCV
from sklearn import ensemble
dataset=read_csv("/content/drive/MyDrive/Datasets/CustomerChurn.csv")
dataset['Gender']=dataset['Gender'].map({'F':1,'M':0}) #Encoding
dataset['Attrition_Flag']=dataset['Attrition_Flag'].map({'Existing Customer':1,'Attrited Customer':0})
data2=get_dummies(dataset,['Education_Level','Income_Category','Marital_Status','Card_Category']) # One hot Encoding
x=data2.drop(['Attrition_Flag'], axis=1)
y=data2['Attrition_Flag']
x_scaled=StandardScaler().fit_transform(x)  #Scaling
x_train, x_test, y_train, y_test = train_test_split( x_scaled, y, test_size = 0.2, random_state = 100) #Splitting
x_train,y_train = SMOTE(random_state = 101).fit_resample(x_train,y_train) #Balancing

"""GridsearchCV with pipeline"""

from imblearn.pipeline import Pipeline
RF_classifier1 = Pipeline([('balancing', SMOTE(random_state = 50)),
        ('classification', ensemble.RandomForestClassifier(criterion='entropy', max_features='auto', random_state=5) )]) # building classifier
no_trees = {'classification__n_estimators': [20,40,60,80,100,120]}
Grid_search = GridSearchCV(estimator=RF_classifier1, param_grid=no_trees, scoring='precision', cv=5)
Grid_search.fit(x_scaled, y)

best_parameters = Grid_search.best_params_
print(best_parameters)
best_result = Grid_search.best_score_
print(best_result)

"""Random Forest Classifier with best no of trees"""

RF_classifier2 = ensemble.RandomForestClassifier(n_estimators=40, criterion='entropy', max_features='auto', random_state=5)# Building classifier
RF_classifier2.fit(x_train,y_train) #training
y_pred = RF_classifier2.predict(x_test)# testing
Best_features = Series(RF_classifier2.feature_importances_, index=list(x)).sort_values(ascending=False)
print(Best_features)

# Evaluation
from sklearn import metrics
precision = metrics.precision_score(y_test, y_pred)
print (precision)

"""GridSearchCv using Pipeline selecting best features

"""

x2 = data2[['Total_Trans_Ct','Total_Trans_Amt','Total_Revolving_Bal','Months_Inactive','Total_Relationship_Count']] #Features
x_scaled = StandardScaler().fit_transform(x2)

RF_classifier3 = Pipeline([('balancing', SMOTE(random_state = 50)),
('classification', ensemble.RandomForestClassifier(criterion='entropy', max_features='auto', random_state=5) )])
no_trees = {'classification__n_estimators': [10,20,30,40,50,60]}
grid_search2 = GridSearchCV(estimator=RF_classifier3, param_grid=no_trees, scoring='precision', cv=5)
grid_search2.fit(x_scaled, y)

best_parameters = grid_search2.best_params_
print(best_parameters)
best_result = grid_search2.best_score_
print(best_result)

"""Random Forest with Best no of trees"""

RF_classifier2 = ensemble.RandomForestClassifier(n_estimators=50, criterion='entropy', max_features='auto', random_state=5) #Building classifier
RF_classifier2.fit(x_train,y_train) #training
y_pred=RF_classifier2.predict(x_test) #testing
Best_features = Series(RF_classifier2.feature_importances_,index=list(x)).sort_values(ascending=False)
print(Best_features)

#Evaluation
from sklearn import metrics
precision = metrics.precision_score(y_test, y_pred)
print (precision)

"""GridSearchCv Iteration for better evaluation

"""

x2 = data2[['Total_Trans_Ct','Total_Trans_Amt','Total_Revolving_Bal','Months_Inactive','Total_Relationship_Count']] #Features
x_scaled = StandardScaler().fit_transform(x2)

RF_classifier3 = Pipeline([('balancing', SMOTE(random_state = 50)),
('classification', ensemble.RandomForestClassifier(criterion='entropy', max_features='auto', random_state=5) )])
no_trees = {'classification__n_estimators': [15,30,45,60,75,90]}
grid_search2 = GridSearchCV(estimator=RF_classifier3, param_grid=no_trees, scoring='precision', cv=5)
grid_search2.fit(x_scaled, y)

best_parameters = grid_search2.best_params_
print(best_parameters)
best_result = grid_search2.best_score_
print(best_result)

"""Random Forest Iteration for better evaluation"""

RF_classifier2 = ensemble.RandomForestClassifier(n_estimators=45, criterion='entropy', max_features='auto', random_state=5) #Building classifier
RF_classifier2.fit(x_train,y_train) #training
y_pred=RF_classifier2.predict(x_test) #testing
Best_features = Series(RF_classifier2.feature_importances_,index=list(x)).sort_values(ascending=False)
print(Best_features)

#Evaluation
from sklearn import metrics
precision = metrics.precision_score(y_test, y_pred)
print (precision)

"""Support Vector Classifier

"""

from sklearn import svm
from sklearn.model_selection import GridSearchCV

SVM_classifier1 = Pipeline([('balancing', SMOTE(random_state = 50)),('classification', svm.SVC(random_state=5) ) ]) # bulilding classifier
kernels_c = {'classification__kernel': ['linear','poly','rbf','sigmoid'], 'classification__C': [.001,.01,.1,1,10,100,200]}
grid_search = GridSearchCV(estimator=SVM_classifier1, param_grid=kernels_c, scoring='precision', cv=5)
grid_search.fit(x_scaled, y)

best_parameters = grid_search.best_params_
print(best_parameters)
best_result = grid_search.best_score_
print(best_result)

"""Support Vector Regular Classifier"""

from sklearn import svm
SV_classifier3 = svm.SVC(kernel='linear', random_state=5)  # Building classifier
SV_classifier3.fit(x_train, y_train) # Training
y_pred1= SV_classifier3.predict(x_test)  #Testing

"""Evaluation"""

from sklearn import metrics
Accuracy=metrics.accuracy_score(y_test, y_pred1) # calculating accuaracy
print("Accuracy: ", Accuracy)
con_matrix = metrics.confusion_matrix(y_test, y_pred1)
print (con_matrix)
recall = metrics.recall_score(y_test, y_pred1)
print (recall)
percision=metrics.precision_score(y_test, y_pred1)
print(percision)